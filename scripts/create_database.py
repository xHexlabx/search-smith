# file: create_database.py
import os
import json
from dotenv import load_dotenv
from langchain_community.vectorstores import Chroma
# !‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: ‡πÉ‡∏ä‡πâ import ‡∏à‡∏≤‡∏Å‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡∏à‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document

def main():
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Database ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Local Model ‡∏à‡∏≤‡∏Å HuggingFace
    """
    # --- 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ---
    print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î Environment Variables...")
    load_dotenv()

    # ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Token ‡πÅ‡∏•‡πâ‡∏ß
    print("‡πÇ‡∏´‡∏°‡∏î Local Embedding: ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ API Token")

    # --- 2. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
    DOCUMENTS_JSON_PATH = 'databases/documents/documents.json'
    print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå '{DOCUMENTS_JSON_PATH}'...")
    try:
        with open(DOCUMENTS_JSON_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå '{DOCUMENTS_JSON_PATH}'")
        return

    print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÉ‡∏´‡πâ Tags...")
    documents_for_db = []
    for item in data:
        metadata = item['metadata']
        original_content = item['page_content']
        
        tags_as_string = ", ".join(metadata['tags']) if isinstance(metadata.get('tags'), list) else metadata.get('tags', '')
        metadata['tags'] = tags_as_string
        
        enhanced_content = f"TAGS: {tags_as_string}\n---\n{original_content}"
        documents_for_db.append(Document(page_content=enhanced_content, metadata=metadata))

    print(f"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß {len(documents_for_db)} ‡∏Ç‡πâ‡∏≠")

    # --- 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store ‡∏î‡πâ‡∏ß‡∏¢ Local Hugging Face Model ---
    
    # !‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: ‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
    print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î Local Embedding Model...")
    print("(‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏≤‡∏ô‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£)")
    
    model_name = "sentence-transformers/all-mpnet-base-v2"
    model_kwargs = {'device': 'cpu'}
    encode_kwargs = {'normalize_embeddings': False} # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏£‡∏∞‡∏ö‡∏∏
    
    embeddings = HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs=model_kwargs,
        encode_kwargs=encode_kwargs
    )
    print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• '{model_name}' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DB ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞
    VECTOR_STORE_PATH = "databases/chroma_db_problems_local_mpnet"
    print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏õ‡∏¢‡∏±‡∏á '{VECTOR_STORE_PATH}'...")

    try:
        Chroma.from_documents(
            documents=documents_for_db,
            embedding=embeddings,
            persist_directory=VECTOR_STORE_PATH
        )
        print("\nüéâ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store ‡∏î‡πâ‡∏ß‡∏¢ Local Model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

    except Exception as e:
        print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store: {e}")

if __name__ == "__main__":
    main()